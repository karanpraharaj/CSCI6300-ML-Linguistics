{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "1cadc8a6-ac6c-487f-b879-15638bf4deba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "e43a031a-fc1c-4634-a2a7-fd9d8df7399c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def constituents(word, n=3):\n",
    "    const_list = []\n",
    "    for i in range(0,len(word)-(n-1)):\n",
    "        const_list.append(word[i:i+n])\n",
    "    const_sent = ' '.join(const_list)\n",
    "    return const_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "bd42f1fd-daf1-4811-8a7e-e0c40f55c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "def generate_table():\n",
    "    txtfiles = []\n",
    "    for file in glob.glob(\"hw4data/*.txt\"):\n",
    "        file_name = file.split('/')[-1].split('.txt')[0]\n",
    "        txtfiles.append(file_name)\n",
    "        data[file_name] = pd.read_csv(file, sep = '\\t', header = None, names = ['label', 'word'])\n",
    "        \n",
    "    # Lower-casing and word constituent generation.\n",
    "    for i in data:\n",
    "        data[i]['word'] = data[i]['word'].apply(lambda x: unidecode(x.lower()))\n",
    "        data[i]['word_constituents'] = data[i]['word'].apply(constituents)\n",
    "    \n",
    "    # for i in data:\n",
    "    #    all_words[i] = data[i]['word']\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = generate_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "0f053692-e198-41fc-b030-5c61533081f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = {}\n",
    "def generate_corpora():\n",
    "    for i in data:\n",
    "        corpus[i] = list(data[i]['word_constituents'])\n",
    "    \n",
    "    return corpus\n",
    "\n",
    "corpus = generate_corpora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "395b5e2f-4fef-4844-b198-54ea1dabee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = {}, {}\n",
    "X_train, y_train = {}, {}\n",
    "X_train_cts = {}\n",
    "X_test, y_test = {}, {}\n",
    "X_test_cts = {}\n",
    "vectorizer = {}\n",
    "\n",
    "def data_splitter():\n",
    "    \n",
    "    for i in data:\n",
    "        X[i] = corpus[i]\n",
    "        y[i] = data[i]['label']\n",
    "        X_train[i], X_test[i], y_train[i], y_test[i] = train_test_split(X[i], y[i], train_size=0.90, test_size=0.10, random_state=101)\n",
    "        vectorizer[i] = CountVectorizer()\n",
    "        X_train_cts[i] = vectorizer[i].fit_transform(X_train[i])\n",
    "        X_test_cts[i] = vectorizer[i].transform(X_test[i])\n",
    "    \n",
    "    return X_train_cts, y_train, X_test_cts, y_test\n",
    "\n",
    "X_train, y_train, X_test, y_test = data_splitter()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b8efd-10b6-4701-91d3-84814c31d04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a1bc9bc4-f16b-40b9-b01a-401047f6c91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET: de_v\n",
      "Training set shape:  (1643, 1850)\n",
      "Test set shape:  (1643,)\n",
      "==========================================\n",
      "DATASET: es_v\n",
      "Training set shape:  (3469, 2204)\n",
      "Test set shape:  (3469,)\n",
      "==========================================\n",
      "DATASET: fi_v\n",
      "Training set shape:  (6344, 2678)\n",
      "Test set shape:  (6344,)\n",
      "==========================================\n",
      "DATASET: fi_na\n",
      "Training set shape:  (5399, 3280)\n",
      "Test set shape:  (5399,)\n",
      "==========================================\n",
      "DATASET: de_n\n",
      "Training set shape:  (2307, 2862)\n",
      "Test set shape:  (2307,)\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "## A sanity check for good measure.\n",
    "\n",
    "for i in X_train:\n",
    "    print(f\"DATASET: {i}\")\n",
    "    print(\"Training set shape: \", X_train[i].shape)\n",
    "    print(\"Test set shape: \", y_train[i].shape)\n",
    "    print(\"==========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a610975b-52fe-46ea-918c-871da8d31728",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf7 = LinearSVC(random_state=42, tol=1e-5, max_iter=1000, C=0.5, fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "d7fe6da3-6b6c-4be0-bec8-4739292561ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.5, fit_intercept=False, random_state=42, tol=1e-05)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.fit(X_train['de_n'], y_train['de_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ada1dd-e79e-4ba4-b2dd-50fc936883e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "b8b51055-301a-4136-95cb-cbc662097b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf7.predict(X_test['de_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "e4f38a12-25bd-41b0-bb4c-763e54b033fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6848249027237354"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test['de_n'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "61cd7309-3250-4a18-ae8e-107786c34e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto')"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svc = SVC(gamma='auto')\n",
    "clf_svc.fit(X_train['de_n'], y_train['de_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "0b9ceeaf-d265-4cdb-b1c3-af94cb991641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2490272373540856"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf_svc.predict(X_test['de_n'])\n",
    "accuracy_score(y_test['de_n'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "7cb48dff-1ed8-4555-9228-cc9ea5e9e696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5252918287937743"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train['de_n'], y_train['de_n'])\n",
    "\n",
    "y_pred = mnb.predict(X_test['de_n'])\n",
    "accuracy_score(y_test['de_n'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "dbdb4a11-ee16-4008-8bbd-0e0b3676b43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=9, weights='distance')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    ">>> neigh = KNeighborsClassifier(n_neighbors=9, weights='distance')\n",
    ">>> neigh.fit(X_train['de_n'], y_train['de_n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "518b1db0-0a09-46fa-98ca-4c67651deed2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42412451361867703"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = neigh.predict(X_test['de_n'])\n",
    "accuracy_score(y_test['de_n'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c610816-43f1-4e69-b8f8-a8fcec468e14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
